{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4 — Task 1: Embeddings and Projections\n",
    "\n",
    "**Goal:** Construct property embeddings and apply dimensionality reduction to obtain 2D projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import json\n",
    "\n",
    "print(f\"NumPy {np.__version__}\")\n",
    "print(f\"Pandas {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('sf_property_data_clean.parquet')\n",
    "\n",
    "# Filter to 2015-2023\n",
    "df = df[(df['year'] >= 2015) & (df['year'] <= 2023)]\n",
    "\n",
    "# Keep records with essential fields\n",
    "required_cols = ['latitude', 'longitude', 'total_assessed_value', 'property_area', \n",
    "                 'year', 'neighborhood', 'number_of_bedrooms', 'number_of_bathrooms']\n",
    "df = df.dropna(subset=required_cols)\n",
    "\n",
    "# Compute building age (fill missing year_property_built with median)\n",
    "if 'year_property_built' in df.columns:\n",
    "    median_year_built = df['year_property_built'].median()\n",
    "    df['year_property_built'] = df['year_property_built'].fillna(median_year_built)\n",
    "    df['building_age'] = 2023 - df['year_property_built']\n",
    "    df['building_age'] = df['building_age'].clip(0, 150)\n",
    "else:\n",
    "    df['building_age'] = 50\n",
    "\n",
    "# Filter outliers using IQR method\n",
    "def remove_outliers(df, col):\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower = Q1 - 1.5 * IQR\n",
    "    upper = Q3 + 1.5 * IQR\n",
    "    return df[(df[col] >= lower) & (df[col] <= upper)]\n",
    "\n",
    "df = remove_outliers(df, 'total_assessed_value')\n",
    "df = remove_outliers(df, 'property_area')\n",
    "\n",
    "print(f\"Records after cleaning: {len(df):,}\")\n",
    "print(f\"Years: {df['year'].min()} - {df['year'].max()}\")\n",
    "print(f\"Neighborhoods: {df['neighborhood'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "**Numerical Features (log-transformed and normalized):**\n",
    "- Property value, area, bedrooms, bathrooms, building age\n",
    "\n",
    "**Spatial Features:**\n",
    "- Latitude, longitude (normalized)\n",
    "- Distance to downtown (37.7749°N, 122.4194°W)\n",
    "\n",
    "**Temporal Features:**\n",
    "- Year (normalized 2015-2023)\n",
    "- COVID period encoding (pre/during/post)\n",
    "\n",
    "**Categorical Features (one-hot encoded):**\n",
    "- Neighborhood (41 districts)\n",
    "\n",
    "**Final dimensionality:** 54 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical features with log transform\n",
    "df['log_value'] = np.log1p(df['total_assessed_value'])\n",
    "df['log_area'] = np.log1p(df['property_area'])\n",
    "df['bedrooms_capped'] = df['number_of_bedrooms'].clip(0, 10)\n",
    "df['bathrooms_capped'] = df['number_of_bathrooms'].clip(0, 8)\n",
    "\n",
    "# Spatial features\n",
    "downtown_lat, downtown_lon = 37.7749, -122.4194\n",
    "df['distance_to_downtown'] = np.sqrt(\n",
    "    (df['latitude'] - downtown_lat)**2 + (df['longitude'] - downtown_lon)**2\n",
    ")\n",
    "\n",
    "# Temporal features\n",
    "df['year_normalized'] = (df['year'] - 2015) / (2023 - 2015)\n",
    "df['pre_covid'] = (df['year'] < 2020).astype(int)\n",
    "df['covid_era'] = ((df['year'] >= 2020) & (df['year'] <= 2021)).astype(int)\n",
    "df['post_covid'] = (df['year'] >= 2022).astype(int)\n",
    "\n",
    "# One-hot encode neighborhood\n",
    "neighborhood_dummies = pd.get_dummies(df['neighborhood'], prefix='nbhd')\n",
    "\n",
    "# Assemble feature matrix\n",
    "numerical_features = [\n",
    "    'log_value', 'log_area', 'bedrooms_capped', 'bathrooms_capped', 'building_age',\n",
    "    'latitude', 'longitude', 'distance_to_downtown',\n",
    "    'year_normalized', 'pre_covid', 'covid_era', 'post_covid'\n",
    "]\n",
    "\n",
    "X = pd.concat([df[numerical_features], neighborhood_dummies], axis=1)\n",
    "\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "print(f\"Features: {X.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(f\"Missing values before cleaning: {X.isnull().sum().sum()}\")\n",
    "\n",
    "# Fill missing values with column means\n",
    "X = X.fillna(X.mean())\n",
    "\n",
    "# Verify no missing values remain\n",
    "print(f\"Missing values after cleaning: {X.isnull().sum().sum()}\")\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(f\"Scaled embeddings shape: {X_scaled.shape}\")\n",
    "print(f\"Mean: {X_scaled.mean():.4f}, Std: {X_scaled.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction\n",
    "\n",
    "### Iteration 1: PCA only (raw features)\n",
    "**Issue:** Value and area dominated due to scale differences; neighborhoods didn't separate\n",
    "\n",
    "### Iteration 2: Normalized + PCA + t-SNE\n",
    "**Improvement:** Clear neighborhood clustering in t-SNE; PCA shows value gradients\n",
    "\n",
    "### Iteration 3: Added temporal features\n",
    "**Result:** COVID-era properties form more distinct patterns in both PCA and t-SNE projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA (global structure)\n",
    "pca = PCA(n_components=2, random_state=99)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "print(f\"PCA variance explained: {pca.explained_variance_ratio_}\")\n",
    "print(f\"Total variance: {pca.explained_variance_ratio_.sum():.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-SNE (local neighborhoods) \n",
    "sample_size = 100000\n",
    "sample_idx = np.random.RandomState(999).choice(len(X_scaled), size=sample_size, replace=False)\n",
    "\n",
    "tsne = TSNE(n_components=2, perplexity=30, random_state=999)\n",
    "X_tsne_sample = tsne.fit_transform(X_scaled[sample_idx])\n",
    "\n",
    "# Create full array with NaNs for non-sampled points\n",
    "X_tsne = np.full((len(X_scaled), 2), np.nan)\n",
    "X_tsne[sample_idx] = X_tsne_sample\n",
    "\n",
    "print(f\"t-SNE computed for {sample_size:,} points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble output dataframe\n",
    "embeddings_2d = pd.DataFrame({\n",
    "    'property_id': range(len(df)),\n",
    "    'neighborhood': df['neighborhood'].values,\n",
    "    'year': df['year'].values,\n",
    "    'total_assessed_value': df['total_assessed_value'].values,\n",
    "    'property_area': df['property_area'].values,\n",
    "    'number_of_bedrooms': df['number_of_bedrooms'].values,\n",
    "    'number_of_bathrooms': df['number_of_bathrooms'].values,\n",
    "    'building_age': df['building_age'].values,\n",
    "    'latitude': df['latitude'].values,\n",
    "    'longitude': df['longitude'].values,\n",
    "    'pca_x': X_pca[:, 0],\n",
    "    'pca_y': X_pca[:, 1],\n",
    "    'tsne_x': X_tsne[:, 0],\n",
    "    'tsne_y': X_tsne[:, 1]\n",
    "})\n",
    "\n",
    "print(f\"Output dataframe: {embeddings_2d.shape}\")\n",
    "embeddings_2d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as JSON for web interface\n",
    "embeddings_2d.to_json('embeddings_2d.json', orient='records')\n",
    "print(\"Saved embeddings_2d.json\")\n",
    "\n",
    "# Also save as CSV\n",
    "embeddings_2d.to_csv('embeddings_2d.csv', index=False)\n",
    "print(\"Saved embeddings_2d.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
